{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-12-23T12:23:23.949179Z",
     "start_time": "2024-12-23T12:23:23.921533Z"
    }
   },
   "source": [
    "from model.recommender import UserKNN, MatrixFactorization\n",
    "from model import user\n",
    "from datetime import timedelta\n",
    "import glob\n",
    "import tqdm\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def filtering_training_data(training_dataset, min_activity):\n",
    "    # Count the number of rows per user\n",
    "    user_counts = training_dataset['uid'].value_counts()\n",
    "    # Get the users with at least x rows\n",
    "    valid_users = user_counts[user_counts >= min_activity].index\n",
    "    # Filter the DataFrame to include only valid users\n",
    "    filtered_dataset = training_dataset[training_dataset['uid'].isin(valid_users)]\n",
    "    return filtered_dataset\n",
    "\n",
    "def create_interaction_matrix(data):\n",
    "    interaction_counts = data.groupby(['uid', 'venueID']).size().reset_index(name='counts')\n",
    "    interaction_matrix = interaction_counts.pivot(index='uid', columns='venueID', values='counts').fillna(0)\n",
    "    return interaction_matrix\n",
    "\n",
    "\n",
    "def calculate_metrics(recommended_venues, real_visited_venues):\n",
    "    recommended_venues = list(recommended_venues)\n",
    "    real_visited_venues = set(real_visited_venues)\n",
    "    \n",
    "    # Calculate hits\n",
    "    hits = [1 if venue in real_visited_venues else 0 for venue in recommended_venues]\n",
    "    \n",
    "    # Precision\n",
    "    precision = sum(hits) / len(recommended_venues) if recommended_venues else 0\n",
    "    \n",
    "    # Recall\n",
    "    recall = sum(hits) / len(real_visited_venues) if real_visited_venues else 0\n",
    "    \n",
    "    # NDCG\n",
    "    dcg = 0\n",
    "    idcg = 0\n",
    "    for i, hit in enumerate(hits, 1):\n",
    "        if hit:\n",
    "            dcg += 1 / np.log2(i + 1)\n",
    "    for i in range(1, len(real_visited_venues) + 1):\n",
    "        idcg += 1 / np.log2(i + 1)\n",
    "    ndcg = dcg / idcg if idcg > 0 else 0\n",
    "    \n",
    "    # MRR\n",
    "    mrr = 0\n",
    "    for i, hit in enumerate(hits, 1):\n",
    "        if hit:\n",
    "            mrr = 1 / i\n",
    "            break\n",
    "    \n",
    "    # Hit Rate\n",
    "    hit_rate = 1 if any(hits) else 0\n",
    "    \n",
    "    return {\n",
    "        'ndcg': ndcg,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'mrr': mrr,\n",
    "        'hitrate': hit_rate\n",
    "    }\n",
    "    "
   ],
   "outputs": [],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-23T12:27:27.327567Z",
     "start_time": "2024-12-23T12:27:27.319225Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# DATASET HYPER-PARAMETERS #\n",
    "city = \"chicago\"\n",
    "city_files = glob.glob('*_visits.csv')\n",
    "data_file = f\"./data/processed/{city}_visits.csv\"\n",
    "train_window = 60  # Training window in days\n",
    "k_days = 7  # Epoch length in days\n",
    "threshold = 100  # Performance degradation threshold (adjust as needed)\n",
    "max_simulation_days = 90  # Maximum number of simulation days\n",
    "min_activity = 5  \n",
    "topK = 20\n",
    "\n",
    "# RECSYS HYPER-PARAMETERS #\n",
    "# MF\n",
    "num_latent_factors = 32\n",
    "# UserKNN\n",
    "num_nearest_neighbors = 5\n"
   ],
   "id": "2fb38147296eb9a4",
   "outputs": [],
   "execution_count": 51
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-23T12:16:12.954995Z",
     "start_time": "2024-12-23T12:16:12.218774Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# DATA LOADING\n",
    "dataset = pd.read_csv(data_file)\n",
    "print(f'Dataset has {len(dataset)} records.')\n",
    "dataset['time'] = pd.to_datetime(dataset['time'])\n",
    "dataset['uid'] = dataset['uid'].astype(int)\n",
    "dataset['venueID'] = dataset['venueID'].astype(str)\n",
    "#drop duplicates\n",
    "dataset = dataset.drop_duplicates()\n",
    "# self.city_name = os.path.basename(data_file).split('_')[0]\n",
    "print(f'Dataset has {len(dataset)} records after removing duplicates.')\n",
    "# Set training period\n",
    "start_date = dataset['time'].min()\n",
    "training_duration = timedelta(days=train_window)\n",
    "t = start_date + training_duration\n",
    "# Training data\n",
    "train_data = dataset[dataset['time'] < t]\n",
    "# Filtering out users with few interactions (visited less than X POIs)\n",
    "train_data = filtering_training_data(train_data, min_activity)\n",
    "# Simulation data==Test data\n",
    "test_data = dataset[dataset['time'] >= t]\n",
    "# Excluding users not present in the training dataset\n",
    "test_data = test_data[test_data['uid'].isin(train_data['uid'].unique())]\n",
    "test_data = test_data[test_data['venueID'].isin(train_data['venueID'].unique())]\n",
    "# Prepare interaction matrix\n",
    "X_train = create_interaction_matrix(train_data)\n"
   ],
   "id": "f06d4f68223168f5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset has 167702 records.\n",
      "Dataset has 167641 records after removing duplicates.\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-23T12:16:15.367778Z",
     "start_time": "2024-12-23T12:16:12.956982Z"
    }
   },
   "cell_type": "code",
   "source": [
    "recommender = MatrixFactorization(num_latent_factors=num_latent_factors)\n",
    "recommender.fit(X_train)\n"
   ],
   "id": "c753a9607af20c3b",
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-23T12:16:15.477695Z",
     "start_time": "2024-12-23T12:16:15.369924Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(f'Test dataset cardinality: {len(test_data)}')\n",
    "# Creating a unique key in both DataFrames by concatenating 'uid' and 'venueID'\n",
    "train_data['key'] = train_data['uid'].astype(str) + '-' + train_data['venueID']\n",
    "test_data['key'] = test_data['uid'].astype(str) + '-' + test_data['venueID']\n",
    "\n",
    "# Identifying keys in train_data\n",
    "train_keys = set(train_data['key'])\n",
    "\n",
    "# Filtering test_data to exclude rows with keys that are in train_keys\n",
    "test_data = test_data[~test_data['key'].isin(train_keys)]\n",
    "\n",
    "# Dropping the key column as it's no longer needed\n",
    "test_data = test_data.drop(columns='key')\n",
    "train_data = train_data.drop(columns='key')\n",
    "print(f'Test dataset cardinality: {len(test_data)}')\n"
   ],
   "id": "da474fb3e61e9982",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test dataset cardinality: 56174\n",
      "Test dataset cardinality: 29124\n"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-23T12:27:43.989198Z",
     "start_time": "2024-12-23T12:27:34.781213Z"
    }
   },
   "cell_type": "code",
   "source": [
    "hitrate_list = list()\n",
    "mrr_list = list()\n",
    "for uid in tqdm.tqdm(test_data['uid'].unique(), 'Users'):\n",
    "    # Get visited venueIDs\n",
    "    test_venueIDs = test_data[test_data['uid'] == uid]['venueID'].values\n",
    "    # Create user object\n",
    "    user_object = user.User(uid, pd.Series(data={'venueID': train_data[train_data['uid'] == uid].venueID.unique()}), None)\n",
    "    recommended_venues = recommender.return_topK(user_object, topK)\n",
    "    metrics_dict = calculate_metrics(recommended_venues, test_venueIDs)\n",
    "    hitrate_list.append(metrics_dict['hitrate'])\n",
    "    mrr_list.append(metrics_dict['mrr'])\n",
    "    "
   ],
   "id": "543595a0071f2120",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Users: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1024/1024 [00:09<00:00, 111.35it/s]\n"
     ]
    }
   ],
   "execution_count": 52
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-23T12:27:43.996363Z",
     "start_time": "2024-12-23T12:27:43.991272Z"
    }
   },
   "cell_type": "code",
   "source": "np.mean(hitrate_list)\n",
   "id": "688b9cc034a8305a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2626953125"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 53
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "9e76900484a7fd8d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
